{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjyCTvHyCEB+RY97n+RWog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adampotton/Group-3-gotta-catch-em-all-/blob/main/Model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hinq2qAYfL8t",
        "outputId": "f80079b3-10b4-4d09-d451-3f0ab264e27d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_directory = \"/content/drive/My Drive/5Pokemon\"\n",
        "\n",
        "# Create a dictionary to store image arrays, using folder names as keys\n",
        "image_arrays_dict = {}\n",
        "\n",
        "# Define a common size for resizing images\n",
        "common_size = (224, 224, 3)  # Common size for RGB images\n",
        "\n",
        "# Loop through each folder in the root directory\n",
        "for folder_name in os.listdir(root_directory):\n",
        "    folder_path = os.path.join(root_directory, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        image_arrays = []\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.lower().endswith((\".jpg\", \".png\")):\n",
        "                image_path = os.path.join(folder_path, filename)\n",
        "                img = Image.open(image_path).convert(\"RGB\")  # Convert to RGB format\n",
        "                img_resized = img.resize((common_size[1], common_size[0]), Image.ANTIALIAS)\n",
        "                img_array = np.array(img_resized)\n",
        "                image_arrays.append(img_array)\n",
        "        image_arrays = np.array(image_arrays)\n",
        "        image_arrays_dict[folder_name] = image_arrays\n",
        "\n",
        "# Combine all image arrays into a single array\n",
        "all_images = np.concatenate(list(image_arrays_dict.values()), axis=0)\n",
        "\n",
        "\n",
        "for folder_name, image_array in image_arrays_dict.items():\n",
        "    print(f\"Shape of the image array for folder '{folder_name}': {image_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AGAIgoWfL1R",
        "outputId": "99ce6658-68fa-4f03-e9be-2de36ed872c3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-896b65ba6408>:18: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img_resized = img.resize((common_size[1], common_size[0]), Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the image array for folder 'Charmander': (51, 224, 224, 3)\n",
            "Shape of the image array for folder 'Eevee': (37, 224, 224, 3)\n",
            "Shape of the image array for folder 'Pikachu': (60, 224, 224, 3)\n",
            "Shape of the image array for folder 'Squirtle': (52, 224, 224, 3)\n",
            "Shape of the image array for folder 'Bulbasaur': (41, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon_classes = ['Charmander', 'Eevee', 'Pikachu', 'Squirtle', 'Bulbasaur']\n",
        "num_images_per_class = [51, 37, 60, 52, 41]\n",
        "all_labels = np.concatenate([np.full(num, i) for i, num in enumerate(num_images_per_class)])\n",
        "\n",
        "\n",
        "# Assuming you have the image arrays stored in 'all_images' and corresponding labels in 'all_labels'\n",
        "# Make sure 'all_images' and 'all_labels' are NumPy arrays\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "images_tensor = torch.tensor(all_images, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
        "\n",
        "# Create a PyTorch dataset\n",
        "dataset = TensorDataset(images_tensor, labels_tensor)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Number of classes for your Pokémon images\n",
        "num_classes = 5\n",
        "\n",
        "# Number of input channels in your Pokémon images\n",
        "num_input_channels = 3  # Assuming RGB images\n",
        "\n",
        "# Define a simpler model\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 56 * 56, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, num_classes)\n",
        ")\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(images.permute(0, 3, 1, 2))\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the accuracy after each epoch\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for images, labels in train_loader:\n",
        "            outputs = model(images.permute(0, 3, 1, 2))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Adjust the size of true labels tensor dynamically\n",
        "            correct += (predicted[:len(labels)] == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total * 100\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVoN5R32nJa2",
        "outputId": "19d33da8-866d-420d-c005-82d9c06b4396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4], Accuracy: 26.56%\n",
            "Epoch [2/4], Accuracy: 34.85%\n"
          ]
        }
      ]
    }
  ]
}